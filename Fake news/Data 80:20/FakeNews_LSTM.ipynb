{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding, Flatten, Input,MaxPooling1D,Dense, Dropout ,Conv1D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import roc_auc_score , accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from nltk.corpus import wordnet \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = pd.read_csv(r'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12159</td>\n",
       "      <td>Trump Has Gotten The Republican Party Sued For...</td>\n",
       "      <td>Jason Easley</td>\n",
       "      <td>The Washington Post reported : \\nThe Democrati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11921</td>\n",
       "      <td>Hand-Foot-And-Mouth Disease On The Rise: What ...</td>\n",
       "      <td>Dikran Arakelian (noreply@blogger.com)</td>\n",
       "      <td>Share on Facebook Every parents worries about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17066</td>\n",
       "      <td>Show biz: Business and breakthroughs</td>\n",
       "      <td>Vanessa Frank</td>\n",
       "      <td>Show biz: Business and breakthroughs Exclusive...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>728</td>\n",
       "      <td>How Voting Machines Are Programmed In Order To...</td>\n",
       "      <td>pcr3</td>\n",
       "      <td>How Voting Machines Are Programmed In Order To...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6058</td>\n",
       "      <td>Iranians arrested after celebrating ancient Pe...</td>\n",
       "      <td>Kaitlyn Stegall</td>\n",
       "      <td>November 1, 2016 Iranians arrested after celeb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  12159  Trump Has Gotten The Republican Party Sued For...   \n",
       "1  11921  Hand-Foot-And-Mouth Disease On The Rise: What ...   \n",
       "2  17066               Show biz: Business and breakthroughs   \n",
       "3    728  How Voting Machines Are Programmed In Order To...   \n",
       "4   6058  Iranians arrested after celebrating ancient Pe...   \n",
       "\n",
       "                                   author  \\\n",
       "0                            Jason Easley   \n",
       "1  Dikran Arakelian (noreply@blogger.com)   \n",
       "2                           Vanessa Frank   \n",
       "3                                    pcr3   \n",
       "4                         Kaitlyn Stegall   \n",
       "\n",
       "                                                text  label  \n",
       "0  The Washington Post reported : \\nThe Democrati...      1  \n",
       "1  Share on Facebook Every parents worries about ...      1  \n",
       "2  Show biz: Business and breakthroughs Exclusive...      1  \n",
       "3  How Voting Machines Are Programmed In Order To...      1  \n",
       "4  November 1, 2016 Iranians arrested after celeb...      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z dátovej množiny vyberieme len nami potrebné atribúty, teda text spravodajských článkov a ich hodnotenie teda label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data=df_data[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.isnull().values.any()    # kontrola null hodnot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     1\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7598 entries, 0 to 7599\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    7598 non-null   object\n",
      " 1   label   7598 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 178.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data=df_data[df_data['text'].notnull()]\n",
    "df_data[\"text\"]=df_data[\"text\"].str.strip()\n",
    "df_data.text.replace('', np.NaN, inplace=True)###nahradenie prazdneho riadka hodnotou NAN\n",
    "np.sum(df_data.isnull().any(axis=1))\n",
    "df_data[df_data.isnull().any(axis=1)].head()\n",
    "df_data.dropna(inplace=True)  ###odstraneie riadkov NaN\n",
    "df_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.isnull().values.any()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  The Washington Post reported : \\nThe Democrati...      1\n",
      "1  Share on Facebook Every parents worries about ...      1\n",
      "2  Show biz: Business and breakthroughs Exclusive...      1\n",
      "3  How Voting Machines Are Programmed In Order To...      1\n",
      "4  November 1, 2016 Iranians arrested after celeb...      1\n"
     ]
    }
   ],
   "source": [
    "print(df_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7000\n",
       "1     598\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10,7))\n",
    "plot = sns.countplot(x='label', data=pd.DataFrame(df_data['label'].map({False:'Reálne',True:'Falošné'}), columns=['label']),palette=[\"#FF3389\", \"#33BDFF\"])\n",
    "\n",
    "ax = plot.axes\n",
    "ax.set(xlabel=\"Triedy v atribúte label\", ylabel = \"Počet\")\n",
    "\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height() * 100 / df_data.shape[0]:.2f}%',\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha='center', \n",
    "                va='center',\n",
    "                fontsize=8, \n",
    "                color='black',\n",
    "                xytext=(0,7), \n",
    "                textcoords='offset points')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_length = df_data.text.apply(len)\n",
    "data_length.head()\n",
    "plt.figure(figsize = (12, 5))\n",
    "plt.hist(data_length, bins = 60, range = [0, 50000], alpha = 0.5, color = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celkový počet trénovacch príkladov je 6078 z toho  92.43% je reálnych a 7.57% je faločných\n",
      "Celkový počet testovacich príkladov je 1520 z toho 90.92% je reálnych a 9.08% je falošných\n"
     ]
    }
   ],
   "source": [
    "df_data.label.value_counts()\n",
    "x = df_data['text'].fillna(\"fillna\")\n",
    "y = df_data['label'].values\n",
    "\n",
    "SEED = 42\n",
    "x_train,x_test, y_train ,y_test= train_test_split(x, y, test_size=0.2, random_state=SEED)\n",
    "print (\"Celkový počet trénovacch príkladov je {0} z toho  {1:.2f}% je reálnych a {2:.2f}% je faločných\".format(len(x_train),\n",
    "                      (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,(len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
    "\n",
    "print (\"Celkový počet testovacich príkladov je {0} z toho {1:.2f}% je reálnych a {2:.2f}% je falošných\".format(len(x_test),\n",
    "                      (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,(len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítanie slovníka GloVe\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 300 \n",
    "max_features = 50000 \n",
    "max_length = 2500 \n",
    "\n",
    "print(\"Načítanie slovníka GloVe\")\n",
    "EMBEDDING_FILE = '../glove.840B.300d.txt' \n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('',EMBEDDING_FILE), encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacia\n",
      "103870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(103870, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tokenizacia\")\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "###sekvenice kazde cislo zobrazuje jedno slovo vo vete\n",
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "\n",
    "x_train_seq = pad_sequences(sequences_train, maxlen=max_length) \n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)\n",
    "embedding_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 2500, 300)         31161000  \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,397,289\n",
      "Trainable params: 31,397,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words,EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trénovanie modelu...\n",
      "Epoch 1/5\n",
      "171/171 [==============================] - 455s 3s/step - loss: 0.2917 - acc: 0.8891 - val_loss: 0.1442 - val_acc: 0.9556\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95559, saving model to modelLSTM.hdf5\n",
      "Epoch 2/5\n",
      "171/171 [==============================] - 450s 3s/step - loss: 0.1200 - acc: 0.9559 - val_loss: 0.1269 - val_acc: 0.9655\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95559 to 0.96546, saving model to modelLSTM.hdf5\n",
      "Epoch 3/5\n",
      "171/171 [==============================] - 449s 3s/step - loss: 0.0558 - acc: 0.9830 - val_loss: 0.1355 - val_acc: 0.9490\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.96546\n",
      "Epoch 4/5\n",
      "171/171 [==============================] - 450s 3s/step - loss: 0.0179 - acc: 0.9958 - val_loss: 0.1484 - val_acc: 0.9589\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.96546\n",
      "Epoch 5/5\n",
      "171/171 [==============================] - 450s 3s/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.1636 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.96546\n"
     ]
    }
   ],
   "source": [
    "saved_model = \"modelLSTM.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "print('Trénovanie modelu...')\n",
    "history = model.fit(x_train_seq, y_train, batch_size=32, epochs=5, callbacks=[checkpoint], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítanie modelu....\n",
      "Vyhodnotenie...\n",
      "Roc auc skóre je 0.9411900417374525\n",
      "Úspešnosť je 0.9467105263157894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      1382\n",
      "           1       0.93      0.45      0.60       138\n",
      "\n",
      "    accuracy                           0.95      1520\n",
      "   macro avg       0.94      0.72      0.79      1520\n",
      "weighted avg       0.95      0.95      0.94      1520\n",
      "\n",
      "Kontigenčná tabuľka\n",
      "[[1377    5]\n",
      " [  76   62]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Načítanie modelu....\")\n",
    "model = load_model('modelLSTM.hdf5')\n",
    "print(\"Vyhodnotenie...\")\n",
    "y_pred = model.predict(x_test_seq)\n",
    "print('Roc auc skóre je {}'.format(roc_auc_score(y_test,y_pred)))\n",
    "\n",
    "y_int = np.zeros_like(y_pred)\n",
    "y_int[y_pred > 0.5] = 1\n",
    "print('Úspešnosť je {}'.format(accuracy_score(y_test,y_int)))\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(\"Kontigenčná tabuľka\")\n",
    "print(confusion_matrix(y_test, y_int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modely rozsirenia EDA\n",
      "Nahradenie synonym n=6\n"
     ]
    }
   ],
   "source": [
    "print(\"Modely rozsirenia EDA\")\n",
    "\n",
    "print(\"Nahradenie synonym n=6\")\n",
    "stop_words = []\n",
    "for w in stopwords.words('english'):\n",
    "    stop_words.append(w)\n",
    "\n",
    "def get_synonyms(word):\n",
    "    \n",
    "    synonyms = set()\n",
    "    \n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "            synonyms.add(synonym) \n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    \n",
    "    return list(synonyms)\n",
    "def synonym_replacement(words, n=6):\n",
    "    \n",
    "    words = words.split()\n",
    "    \n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word not in stop_words]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    \n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        \n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        \n",
    "        if num_replaced >= n: \n",
    "            break\n",
    "\n",
    "    sentence = ' '.join(new_words)\n",
    "    new_words = sentence.split(' ')\n",
    "\n",
    "    return sentence\n",
    "\n",
    "fake = x_train[y_train==1]\n",
    "x_synonym = fake.apply(synonym_replacement)\n",
    "y_synonym= np.ones(len(x_synonym))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349    Print \\nHave you ever noticed how Washington a...\n",
      "335    The prophecy is coming true. \\nEvery cuck lose...\n",
      "260    Twitter: @ batchelorshow \\nFarming Invented Ma...\n",
      "382    in: Multimedia , Preparedness\\Survival , Scien...\n",
      "45     source Add To The Conversation Using Facebook ...\n",
      "428    ‘It’s for my children.’; Ammon Bundy’s testimo...\n",
      "412    Thursday, 10 November 2016 Pro Rrape and Pilla...\n",
      "440    Last December, Project Veritas caught NYC Demo...\n",
      "436    By wmw_admin on October 28, 2016 Alana Goodman...\n",
      "211    Keywords: Cardiovascular , diabetes , dietary ...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(fake.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday, 10 November 2016 Pro Rrape and Pillage US government declares open season on gaea Scientists have discovered that Gaia, the mythic name given to the Earth Mother Spirit has a demise wish. They sound out it was inconceivable that a so called intelligent entity would overnight destroy the hard won and small achievements of the Paris Accord that took tenner of hard work by the thousands of environmental minions. I mean even DiCaprio did a documentary, what more could we have done cried Environmentalists collectively. There seems no other logical conclusion except gaea just doesn't seem to care she is in accelerated decline with imminent exhaustion and implosion. Conservationists across the world are gob smacked in disbelief that after all the crap the have been through just to get a tiny bit of progress she allows the biggest psychopath on the planet to win the power to declare 'Open Season on Earths Resources'. Big business has already started started moving in the heavy equipment and has vowed to rape every single last gallon on oil from every single place on the earth. Koch Brothers Security guards emboldened by Emperor OctoTrumpus take-over of Trumpica have orders to shoot to kill on sight any environmental protester they see. Security guards from the Confederate Militia have goaded the Greenies with \"Tie your self to a tree now suckers\". Make Jung in the Jungle's day - give this story five thumbs-up (there's no demand to register , the thumbs are just down there!)\n"
     ]
    }
   ],
   "source": [
    "print(x_synonym[412])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday, 10 November 2016 Pro Rrape and Pillage US government declares open season on Gaia \n",
      "Scientists have discovered that Gaia, the mythical name given to the Earth Mother Spirit has a death wish. \n",
      "They said it was inconceivable that a so called intelligent entity would overnight destroy the hard won and small achievements of the Paris Accord that took decades of hard work by the thousands of environmental minions. I mean even DiCaprio did a documentary, what more could we have done cried Environmentalists collectively. \n",
      "There seems no other logical conclusion except Gaia just doesn't seem to care she is in accelerated decline with imminent exhaustion and implosion. \n",
      "Conservationists across the world are gob smacked in disbelief that after all the crap the have been through just to get a tiny bit of progress she allows the biggest psychopath on the planet to win the power to declare 'Open Season on Earths Resources'. \n",
      "Big business has already started started moving in the heavy equipment and has vowed to rape every single last gallon on oil from every single place on the earth. Koch Brothers Security guards emboldened by Emperor OctoTrumpus take-over of Trumpica have orders to shoot to kill on sight any environmental protester they see. Security guards from the Confederate Militia have goaded the Greenies with \"Tie your self to a tree now suckers\". Make Jung in the Jungle's day - give this story five thumbs-up (there's no need to register , the thumbs are just down there!)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[412])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_syn=pd.concat([x_train,x_synonym])\n",
    "y_syn=np.concatenate((y_train,y_synonym), axis=0)\n",
    "y_syn= y_syn.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5618, 1: 460})\n",
      "Counter({0: 5618, 1: 920})\n"
     ]
    }
   ],
   "source": [
    "import collections, numpy\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacia\n",
      "Emmbedings matrix....\n",
      "104182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(104182, 300)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tokenizacia\")\n",
    "tokenizer = Tokenizer(max_features)\n",
    "tokenizer.fit_on_texts(x_syn)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_syn)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "###sekvenice kazde cislo zobrazuje jedno slovo vo vete\n",
    "\n",
    "x_train_seq = pad_sequences(sequences_train, maxlen=max_length) \n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Emmbedings matrix....\")\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)\n",
    "embedding_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 2500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 2500, 300)         31254600  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,490,889\n",
      "Trainable params: 31,490,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training model...\n",
      "Epoch 1/5\n",
      "184/184 [==============================] - 486s 3s/step - loss: 0.2514 - acc: 0.9251 - val_loss: 0.8998 - val_acc: 0.5841\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.58410, saving model to LSTM_syn.hdf5\n",
      "Epoch 2/5\n",
      "184/184 [==============================] - 484s 3s/step - loss: 0.1033 - acc: 0.9671 - val_loss: 0.4275 - val_acc: 0.8303\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.58410 to 0.83028, saving model to LSTM_syn.hdf5\n",
      "Epoch 3/5\n",
      "184/184 [==============================] - 484s 3s/step - loss: 0.0353 - acc: 0.9888 - val_loss: 0.2289 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.83028 to 0.93884, saving model to LSTM_syn.hdf5\n",
      "Epoch 4/5\n",
      "184/184 [==============================] - 485s 3s/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.1591 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.93884 to 0.96942, saving model to LSTM_syn.hdf5\n",
      "Epoch 5/5\n",
      "184/184 [==============================] - 485s 3s/step - loss: 6.9776e-04 - acc: 1.0000 - val_loss: 0.1224 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.96942 to 0.98624, saving model to LSTM_syn.hdf5\n"
     ]
    }
   ],
   "source": [
    "####MODELOVANIE\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words,EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "saved_model_syn= \"LSTM_syn.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model_syn, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit(x_train_seq, y_syn,epochs=5, batch_size=32,callbacks=[checkpoint],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model....\n",
      "Vyhodnotenie...\n",
      "Roc auc skóre je 0.9493907170871873\n",
      "Úspešnosť modelu je  0.9585526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1382\n",
      "           1       0.85      0.66      0.74       138\n",
      "\n",
      "    accuracy                           0.96      1520\n",
      "   macro avg       0.91      0.82      0.86      1520\n",
      "weighted avg       0.96      0.96      0.96      1520\n",
      "\n",
      "[[1366   16]\n",
      " [  47   91]]\n",
      "Counter({0: 5618, 1: 460})\n",
      "Counter({0: 5618, 1: 920})\n"
     ]
    }
   ],
   "source": [
    "######VYHODNOTENIE\n",
    "print(\"Loading model....\")\n",
    "model = load_model('LSTM_syn.hdf5')\n",
    "print(\"Vyhodnotenie...\")\n",
    "y_pred = model.predict(x_test_seq)\n",
    "print('Roc auc skóre je {}'.format(roc_auc_score(y_test,y_pred)))\n",
    "\n",
    "y_int = np.zeros_like(y_pred)\n",
    "y_int[y_pred > 0.5] = 1\n",
    "print('Úspešnosť modelu je  {}'.format(accuracy_score(y_test,y_int)))\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))\n",
    "\n",
    "import collections, numpy\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nahradenie synonym n=5\n",
      "Tokenizacia\n",
      "Emmbedings matrix....\n",
      "104165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(104165, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Nahradenie synonym n=5\")\n",
    "stop_words = []\n",
    "for w in stopwords.words('english'):\n",
    "    stop_words.append(w)\n",
    "\n",
    "def get_synonyms(word):\n",
    "    \n",
    "    synonyms = set()\n",
    "    \n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "            synonyms.add(synonym) \n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    \n",
    "    return list(synonyms)\n",
    "def synonym_replacement(words, n=5):\n",
    "    \n",
    "    words = words.split()\n",
    "    \n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word not in stop_words]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    \n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        \n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            num_replaced += 1\n",
    "        \n",
    "        if num_replaced >= n: \n",
    "            break\n",
    "\n",
    "    sentence = ' '.join(new_words)\n",
    "    new_words = sentence.split(' ')\n",
    "\n",
    "    return sentence\n",
    "\n",
    "fake = x_train[y_train==1]\n",
    "x_synonym = fake.apply(synonym_replacement)\n",
    "y_synonym= np.ones(len(x_synonym))\n",
    "\n",
    "x_syn=pd.concat([x_train,x_synonym])\n",
    "y_syn=np.concatenate((y_train,y_synonym), axis=0)\n",
    "y_syn= y_syn.astype('int64')\n",
    "\n",
    "print(\"Tokenizacia\")\n",
    "tokenizer = Tokenizer(max_features)\n",
    "tokenizer.fit_on_texts(x_syn)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_syn)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_seq = pad_sequences(sequences_train, maxlen=max_length) \n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Emmbedings matrix....\")\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)\n",
    "embedding_matrix.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 2500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 2500, 300)         31249500  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,485,789\n",
      "Trainable params: 31,485,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training model...\n",
      "Epoch 1/5\n",
      "184/184 [==============================] - 487s 3s/step - loss: 0.2672 - acc: 0.9128 - val_loss: 0.7034 - val_acc: 0.6514\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.65138, saving model to LSTM_syn5.hdf5\n",
      "Epoch 2/5\n",
      "184/184 [==============================] - 485s 3s/step - loss: 0.1174 - acc: 0.9609 - val_loss: 0.2152 - val_acc: 0.9190\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.65138 to 0.91896, saving model to LSTM_syn5.hdf5\n",
      "Epoch 3/5\n",
      "184/184 [==============================] - 484s 3s/step - loss: 0.0381 - acc: 0.9864 - val_loss: 0.1461 - val_acc: 0.9602\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91896 to 0.96024, saving model to LSTM_syn5.hdf5\n",
      "Epoch 4/5\n",
      "184/184 [==============================] - 485s 3s/step - loss: 0.0059 - acc: 0.9988 - val_loss: 0.1692 - val_acc: 0.9679\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.96024 to 0.96789, saving model to LSTM_syn5.hdf5\n",
      "Epoch 5/5\n",
      "184/184 [==============================] - 485s 3s/step - loss: 5.3531e-04 - acc: 1.0000 - val_loss: 0.1878 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.96789 to 0.96942, saving model to LSTM_syn5.hdf5\n"
     ]
    }
   ],
   "source": [
    "####MODELOVANIE\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words,EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "saved_model= \"LSTM_syn5.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit(x_train_seq, y_syn,epochs=5, batch_size=32,callbacks=[checkpoint],validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model....\n",
      "Vyhodnotenie...\n",
      "Roc auc skóre je 0.9473877388368044\n",
      "Úspešnosť modelu je  0.9559210526315789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1382\n",
      "           1       0.93      0.56      0.70       138\n",
      "\n",
      "    accuracy                           0.96      1520\n",
      "   macro avg       0.94      0.78      0.84      1520\n",
      "weighted avg       0.95      0.96      0.95      1520\n",
      "\n",
      "[[1376    6]\n",
      " [  61   77]]\n",
      "Counter({0: 5618, 1: 460})\n",
      "Counter({0: 5618, 1: 920})\n"
     ]
    }
   ],
   "source": [
    "######VYHODNOTENIE\n",
    "print(\"Loading model....\")\n",
    "model = load_model('LSTM_syn5.hdf5')\n",
    "print(\"Vyhodnotenie...\")\n",
    "y_pred = model.predict(x_test_seq)\n",
    "print('Roc auc skóre je {}'.format(roc_auc_score(y_test,y_pred)))\n",
    "\n",
    "y_int = np.zeros_like(y_pred)\n",
    "y_int[y_pred > 0.5] = 1\n",
    "print('Úspešnosť modelu je  {}'.format(accuracy_score(y_test,y_int)))\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))\n",
    "\n",
    "import collections, numpy\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_syn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nahodne vloženie n=6\n"
     ]
    }
   ],
   "source": [
    "####NAHODNE VLOZENIE\n",
    "print(\"Nahodne vloženie n=6\")\n",
    "def random_insertion(words, n=6):\n",
    "    \n",
    "    words = words.split()\n",
    "    new_words = words.copy()\n",
    "    \n",
    "    for _ in range(n):\n",
    "        add_word(new_words)\n",
    "        \n",
    "    sentence = ' '.join(new_words)\n",
    "    return sentence\n",
    "\n",
    "def add_word(new_words):\n",
    "    \n",
    "    synonyms = []\n",
    "    counter = 0\n",
    "    \n",
    "    while len(synonyms) < 1:\n",
    "        random_word = new_words[random.randint(0, len(new_words)-1)]\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        counter += 1\n",
    "        if counter >= 10:\n",
    "            return\n",
    "        \n",
    "    random_synonym = synonyms[0]\n",
    "    random_idx = random.randint(0, len(new_words)-1)\n",
    "    new_words.insert(random_idx, random_synonym)\n",
    "    \n",
    "fake = x_train[y_train==1]\n",
    "\n",
    "\n",
    "x_insert = fake.apply(random_insertion)\n",
    "y_insert= np.ones(len(x_insert))\n",
    "\n",
    "x_random_insert=pd.concat([x_train,x_insert])\n",
    "y_random_insert=np.concatenate((y_train,y_insert), axis=0)\n",
    "y_random_insert= y_random_insert.astype('int64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday, 10 November 2016 Pro Rrape and Pillage US government declares open season on Gaia Scientists have discovered that Gaia, lastly the mythical name given to the Earth Mother Spirit has a death wish. They said it was inconceivable that a so called intelligent entity would overnight destroy the hard won and small achievements of the Paris Accord that took decades of hard work by the thousands of environmental minions. I mean even DiCaprio did a documentary, what more could we have done cried Environmentalists collectively. There seems no other logical conclusion except Gaia just doesn't along seem to care she is in accelerated decline with imminent exhaustion and implosion. Conservationists across the world are gob smacked in disbelief that after all the crap the have been through just to get a tiny bit of progress emperor moth she allows the biggest psychopath on the planet to win the power to declare 'Open Season on Earths Resources'. Big business has already started started moving in the heavy equipment and has vowed to rape every single last gallon on oil from every single along place on the earth. Koch Brothers Security  guards emboldened by Emperor OctoTrumpus take-over of Trumpica have orders to shoot to kill indiana on sight any environmental protester they see. Security guards from the Confederate Militia have goaded the Greenies with \"Tie your self to a tree now suckers\". Make Jung in the Jungle's day - give this story five thumbs-up (there's no need to register , the thumbs are just down there!)\n"
     ]
    }
   ],
   "source": [
    "print(x_insert[412])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thursday, 10 November 2016 Pro Rrape and Pillage US government declares open season on Gaia \n",
      "Scientists have discovered that Gaia, the mythical name given to the Earth Mother Spirit has a death wish. \n",
      "They said it was inconceivable that a so called intelligent entity would overnight destroy the hard won and small achievements of the Paris Accord that took decades of hard work by the thousands of environmental minions. I mean even DiCaprio did a documentary, what more could we have done cried Environmentalists collectively. \n",
      "There seems no other logical conclusion except Gaia just doesn't seem to care she is in accelerated decline with imminent exhaustion and implosion. \n",
      "Conservationists across the world are gob smacked in disbelief that after all the crap the have been through just to get a tiny bit of progress she allows the biggest psychopath on the planet to win the power to declare 'Open Season on Earths Resources'. \n",
      "Big business has already started started moving in the heavy equipment and has vowed to rape every single last gallon on oil from every single place on the earth. Koch Brothers Security guards emboldened by Emperor OctoTrumpus take-over of Trumpica have orders to shoot to kill on sight any environmental protester they see. Security guards from the Confederate Militia have goaded the Greenies with \"Tie your self to a tree now suckers\". Make Jung in the Jungle's day - give this story five thumbs-up (there's no need to register , the thumbs are just down there!)\n"
     ]
    }
   ],
   "source": [
    "print(x_train[412])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 5618, 1: 460})\n",
      "Counter({0: 5618, 1: 920})\n"
     ]
    }
   ],
   "source": [
    "import collections, numpy\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_random_insert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacia\n",
      "Emmbedings matrix....\n",
      "104038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(104038, 300)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tokenizacia\")\n",
    "tokenizer = Tokenizer(max_features)\n",
    "tokenizer.fit_on_texts(x_random_insert)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_random_insert)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "\n",
    "x_train_seq = pad_sequences(sequences_train, maxlen=max_length) \n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Emmbedings matrix....\")\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)\n",
    "embedding_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 2500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 2500, 300)         31211400  \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,447,689\n",
      "Trainable params: 31,447,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Training model...\n",
      "Epoch 1/5\n",
      "184/184 [==============================] - 801s 4s/step - loss: 0.2682 - acc: 0.9023 - val_loss: 0.6787 - val_acc: 0.6667\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.66667, saving model to LSTM_insert.hdf5\n",
      "Epoch 2/5\n",
      "184/184 [==============================] - 800s 4s/step - loss: 0.1111 - acc: 0.9628 - val_loss: 0.2835 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.66667 to 0.89144, saving model to LSTM_insert.hdf5\n",
      "Epoch 3/5\n",
      "184/184 [==============================] - 799s 4s/step - loss: 0.0339 - acc: 0.9885 - val_loss: 0.1280 - val_acc: 0.9709\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.89144 to 0.97095, saving model to LSTM_insert.hdf5\n",
      "Epoch 4/5\n",
      "184/184 [==============================] - 797s 4s/step - loss: 0.0084 - acc: 0.9977 - val_loss: 0.2336 - val_acc: 0.9587\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.97095\n",
      "Epoch 5/5\n",
      "184/184 [==============================] - 793s 4s/step - loss: 0.0034 - acc: 0.9985 - val_loss: 0.1867 - val_acc: 0.9725\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97095 to 0.97248, saving model to LSTM_insert.hdf5\n"
     ]
    }
   ],
   "source": [
    "####MODELOVANIE\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words,EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "saved_model = \"LSTM_insert.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    " \n",
    "print('Training model...')\n",
    "history = model.fit(x_train_seq, y_random_insert,epochs=5, batch_size=32,callbacks=[checkpoint],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítanie modelu....\n",
      "Vyhodnotenie...\n",
      "Roc auc skóre je 0.947982864573502\n",
      "Úspešnosť modelu je 0.9539473684210527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1382\n",
      "           1       0.90      0.56      0.69       138\n",
      "\n",
      "    accuracy                           0.95      1520\n",
      "   macro avg       0.93      0.78      0.83      1520\n",
      "weighted avg       0.95      0.95      0.95      1520\n",
      "\n",
      "[[1373    9]\n",
      " [  61   77]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Načítanie modelu....\")\n",
    "model = load_model('LSTM_insert.hdf5')\n",
    "print(\"Vyhodnotenie...\")\n",
    "y_pred = model.predict(x_test_seq)\n",
    "print('Roc auc skóre je {}'.format(roc_auc_score(y_test,y_pred)))\n",
    "\n",
    "y_int = np.zeros_like(y_pred)\n",
    "y_int[y_pred > 0.5] = 1\n",
    "print('Úspešnosť modelu je {}'.format(accuracy_score(y_test,y_int)))\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nahodne výmena n=3\n",
      "Counter({0: 5618, 1: 460})\n",
      "Counter({0: 5618, 1: 920})\n"
     ]
    }
   ],
   "source": [
    "print(\"Nahodne výmena n=3\")\n",
    "def swap_word(new_words):\n",
    "    \n",
    "    random_idx_1 = random.randint(0, len(new_words)-1)\n",
    "    random_idx_2 = random_idx_1\n",
    "    counter = 0\n",
    "    \n",
    "    while random_idx_2 == random_idx_1:\n",
    "        random_idx_2 = random.randint(0, len(new_words)-1)\n",
    "        counter += 1\n",
    "        \n",
    "        if counter > 3:\n",
    "            return new_words\n",
    "    \n",
    "    new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1] \n",
    "    return new_words\n",
    "\n",
    "def random_swap(words, n=3):\n",
    "    \n",
    "    words = words.split()\n",
    "    new_words = words.copy()\n",
    "    \n",
    "    for _ in range(n):\n",
    "        new_words = swap_word(new_words)\n",
    "        \n",
    "    sentence = ' '.join(new_words)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "fake = x_train[y_train==1]\n",
    "\n",
    "\n",
    "x_swap = fake.apply(random_swap)\n",
    "y_swap= np.ones(len(x_swap))\n",
    "\n",
    "x_random_swap=pd.concat([x_train,x_swap])\n",
    "y_random_swap=np.concatenate((y_train,y_swap), axis=0)\n",
    "y_random_swap= y_random_swap.astype('int64')\n",
    "\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_random_swap))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacia\n",
      "Emmbedings matica....\n",
      "103870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(103870, 300)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tokenizacia\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_random_swap)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "###sekvenice kazde cislo zobrazuje jedno slovo vo vete\n",
    "\n",
    "x_train_seq = pad_sequences(sequences_train, maxlen=max_length) \n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Emmbedings matica....\")\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)\n",
    "embedding_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        [(None, 2500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_11 (Embedding)     (None, 2500, 300)         31161000  \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,397,289\n",
      "Trainable params: 31,397,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Trénovanie modelu...\n",
      "Epoch 1/5\n",
      "184/184 [==============================] - 808s 4s/step - loss: 0.2701 - acc: 0.9102 - val_loss: 0.8156 - val_acc: 0.6131\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61315, saving model to LSTM_swap.hdf5\n",
      "Epoch 2/5\n",
      "184/184 [==============================] - 801s 4s/step - loss: 0.0991 - acc: 0.9679 - val_loss: 0.2856 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.61315 to 0.88838, saving model to LSTM_swap.hdf5\n",
      "Epoch 3/5\n",
      "184/184 [==============================] - 803s 4s/step - loss: 0.0248 - acc: 0.9938 - val_loss: 0.1718 - val_acc: 0.9664\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.88838 to 0.96636, saving model to LSTM_swap.hdf5\n",
      "Epoch 4/5\n",
      "184/184 [==============================] - 801s 4s/step - loss: 0.0037 - acc: 0.9993 - val_loss: 0.1219 - val_acc: 0.9694\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.96636 to 0.96942, saving model to LSTM_swap.hdf5\n",
      "Epoch 5/5\n",
      "184/184 [==============================] - 805s 4s/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.1666 - val_acc: 0.9786\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.96942 to 0.97859, saving model to LSTM_swap.hdf5\n"
     ]
    }
   ],
   "source": [
    "####MODELOVANIE\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words,EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "saved_model= \"LSTM_swap.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "print('Trénovanie modelu...')\n",
    "history = model.fit(x_train_seq, y_random_swap,epochs=5, batch_size=32,callbacks=[checkpoint],validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítanie modelu....\n",
      "Vyhodnotenie...\n",
      "Roc auc skóre je 0.9565741731160469\n",
      "Úspešnosť je 0.9559210526315789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1382\n",
      "           1       0.87      0.60      0.71       138\n",
      "\n",
      "    accuracy                           0.96      1520\n",
      "   macro avg       0.92      0.80      0.84      1520\n",
      "weighted avg       0.95      0.96      0.95      1520\n",
      "\n",
      "Kontigenčná tabuľka modelu:\n",
      "[[1370   12]\n",
      " [  55   83]]\n",
      "Counter({0: 5618, 1: 460})\n",
      "Counter({0: 5618, 1: 920})\n"
     ]
    }
   ],
   "source": [
    "print(\"Načítanie modelu....\")\n",
    "model = load_model('LSTM_swap.hdf5')\n",
    "print(\"Vyhodnotenie...\")\n",
    "y_pred = model.predict(x_test_seq)\n",
    "print('Roc auc skóre je {}'.format(roc_auc_score(y_test,y_pred)))\n",
    "\n",
    "y_int = np.zeros_like(y_pred)\n",
    "y_int[y_pred > 0.5] = 1\n",
    "print('Úspešnosť je {}'.format(accuracy_score(y_test,y_int)))\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(\"Kontigenčná tabuľka modelu:\")\n",
    "print(confusion_matrix(y_test, y_int))\n",
    "\n",
    "\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_random_swap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nahodne vymazanie p=0.13\n"
     ]
    }
   ],
   "source": [
    "####NAHODNE VYMAZANIE\n",
    "print(\"Nahodne vymazanie p=0.13\")\n",
    "def random_deletion(words, p=0.13):\n",
    "\n",
    "    words = words.split()\n",
    "    \n",
    "   # zjavne, ak je iba jedno slovo,  ho\n",
    "    if len(words) == 1:\n",
    "        return words\n",
    "\n",
    "    #skutocne mazat slovs pravdepodobnostou str\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > p:\n",
    "            new_words.append(word)\n",
    "\n",
    "    # ak nakoniec \n",
    "    if len(new_words) == 0:\n",
    "        rand_int = random.randint(0, len(words)-1)\n",
    "        return [words[rand_int]]\n",
    "\n",
    "    sentence = ' '.join(new_words)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "\n",
    "\n",
    "x_del = fake.apply(random_deletion)\n",
    "y_del= np.ones(len(x_del))\n",
    "\n",
    "x_random_del=pd.concat([x_train,x_del])\n",
    "y_random_del=np.concatenate((y_train,y_del), axis=0)\n",
    "y_random_del= y_random_del.astype('int64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacia\n",
      "Emmbedings matrix....\n",
      "103870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(103870, 300)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tokenizacia\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_random_del)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_random_del)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "###sekvenice kazde cislo zobrazuje jedno slovo vo vete\n",
    "\n",
    "x_train_seq = pad_sequences(sequences_train, maxlen=max_length) \n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Emmbedings matrix....\")\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)\n",
    "embedding_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 2500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_13 (Embedding)     (None, 2500, 300)         31161000  \n",
      "_________________________________________________________________\n",
      "lstm_13 (LSTM)               (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,397,289\n",
      "Trainable params: 31,397,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Trénovanie modelu...\n",
      "Epoch 1/5\n",
      "184/184 [==============================] - 807s 4s/step - loss: 0.2647 - acc: 0.9135 - val_loss: 1.0364 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.57034, saving model to LSTM_del.hdf5\n",
      "Epoch 2/5\n",
      "184/184 [==============================] - 800s 4s/step - loss: 0.1079 - acc: 0.9630 - val_loss: 0.1865 - val_acc: 0.9297\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.57034 to 0.92966, saving model to LSTM_del.hdf5\n",
      "Epoch 3/5\n",
      "184/184 [==============================] - 801s 4s/step - loss: 0.0343 - acc: 0.9912 - val_loss: 0.1779 - val_acc: 0.9572\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.92966 to 0.95719, saving model to LSTM_del.hdf5\n",
      "Epoch 4/5\n",
      "184/184 [==============================] - 801s 4s/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.1720 - val_acc: 0.9648\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.95719 to 0.96483, saving model to LSTM_del.hdf5\n",
      "Epoch 5/5\n",
      "184/184 [==============================] - 802s 4s/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.2959 - val_acc: 0.9388\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.96483\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words,EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "saved_model= \"LSTM_del.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "print('Trénovanie modelu...')\n",
    "history = model.fit(x_train_seq, y_random_del,epochs=5, batch_size=32,callbacks=[checkpoint],validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítanie modelu....\n",
      "Vyhodnotenie...\n",
      "Roc auc score is 0.9319406866754755\n",
      "Accuracy is 0.9513157894736842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1382\n",
      "           1       0.88      0.54      0.67       138\n",
      "\n",
      "    accuracy                           0.95      1520\n",
      "   macro avg       0.92      0.76      0.82      1520\n",
      "weighted avg       0.95      0.95      0.95      1520\n",
      "\n",
      "[[1372   10]\n",
      " [  64   74]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 5618, 1: 920})"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Načítanie modelu....\")\n",
    "model = load_model('LSTM_del.hdf5')\n",
    "print(\"Vyhodnotenie...\")\n",
    "y_pred = model.predict(x_test_seq)\n",
    "print('Roc auc score is {}'.format(roc_auc_score(y_test,y_pred)))\n",
    "\n",
    "y_int = np.zeros_like(y_pred)\n",
    "y_int[y_pred > 0.5] = 1\n",
    "print('Accuracy is {}'.format(accuracy_score(y_test,y_int)))\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))\n",
    "\n",
    "collections.Counter(y_train)\n",
    "collections.Counter(y_random_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modely rozsirenia EDA\n",
      "Counter({0: 5618, 1: 460})\n",
      "Counter({0: 5618, 1: 2300})\n"
     ]
    }
   ],
   "source": [
    "print(\"Modely rozsirenia EDA\")\n",
    "x_eda=np.concatenate((x_synonym,x_swap,x_insert,x_del,x_train), axis=0)\n",
    "y_eda=np.concatenate((y_synonym,y_swap,y_insert,y_del,y_train), axis=0)\n",
    "y_eda= y_eda.astype('int64')\n",
    "\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_eda))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacia\n",
      "Emmbedings matrix....\n",
      "103870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(103870, 300)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tokenizacia\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_eda)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_seq = pad_sequences(sequences_train, maxlen=max_length) \n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Emmbedings matrix....\")\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)\n",
    "embedding_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        [(None, 2500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_15 (Embedding)     (None, 2500, 300)         31161000  \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,397,289\n",
      "Trainable params: 31,397,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Trénovanie modelu...\n",
      "Epoch 1/5\n",
      "223/223 [==============================] - 969s 4s/step - loss: 0.3924 - acc: 0.8162 - val_loss: 0.0993 - val_acc: 0.9495\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.94949, saving model to LSTM_eda.hdf5\n",
      "Epoch 2/5\n",
      "223/223 [==============================] - 966s 4s/step - loss: 0.0466 - acc: 0.9865 - val_loss: 0.0466 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.94949 to 0.98485, saving model to LSTM_eda.hdf5\n",
      "Epoch 3/5\n",
      "223/223 [==============================] - 965s 4s/step - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0260 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.98485 to 0.99369, saving model to LSTM_eda.hdf5\n",
      "Epoch 4/5\n",
      "223/223 [==============================] - 961s 4s/step - loss: 7.5114e-04 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99369\n",
      "Epoch 5/5\n",
      "223/223 [==============================] - 967s 4s/step - loss: 7.5212e-05 - acc: 1.0000 - val_loss: 0.0506 - val_acc: 0.9899\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99369\n"
     ]
    }
   ],
   "source": [
    "####MODELOVANIE\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words,EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "saved_model= \"LSTM_eda.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "print('Trénovanie modelu...')\n",
    "history = model.fit(x_train_seq, y_eda,epochs=5, batch_size=32,callbacks=[checkpoint],validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítanie modelu....\n",
      "Vyhodnotenie...\n",
      "Roc auc skóre je 0.954246104154869\n",
      "Úspešnosť modelu je 0.9559210526315789\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1382\n",
      "           1       0.87      0.61      0.71       138\n",
      "\n",
      "    accuracy                           0.96      1520\n",
      "   macro avg       0.91      0.80      0.85      1520\n",
      "weighted avg       0.95      0.96      0.95      1520\n",
      "\n",
      "[[1369   13]\n",
      " [  54   84]]\n",
      "Počet real/fake v pôvodnej množine\n",
      "Counter({0: 5618, 1: 460})\n",
      "Počet real/fake v rozširenej množine\n",
      "Counter({0: 5618, 1: 2300})\n"
     ]
    }
   ],
   "source": [
    "print(\"Načítanie modelu....\")\n",
    "model = load_model('LSTM_eda.hdf5')\n",
    "print(\"Vyhodnotenie...\")\n",
    "y_pred = model.predict(x_test_seq)\n",
    "print('Roc auc skóre je {}'.format(roc_auc_score(y_test,y_pred)))\n",
    "\n",
    "y_int = np.zeros_like(y_pred)\n",
    "y_int[y_pred > 0.5] = 1\n",
    "print('Úspešnosť modelu je {}'.format(accuracy_score(y_test,y_int)))\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))\n",
    "\n",
    "print(\"Počet real/fake v pôvodnej množine\")\n",
    "print(collections.Counter(y_train))\n",
    "print(\"Počet real/fake v rozširenej množine\")\n",
    "print(collections.Counter(y_eda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spojenie najlepších metód EDA\n",
      "Counter({0: 5618, 1: 460})\n",
      "Counter({0: 5618, 1: 1840})\n"
     ]
    }
   ],
   "source": [
    "print(\"Spojenie najlepších metód EDA\")\n",
    "x_eda=np.concatenate((x_synonym,x_insert,x_del,x_train), axis=0)\n",
    "y_eda=np.concatenate((y_synonym,y_insert,y_del,y_train), axis=0)\n",
    "y_eda= y_eda.astype('int64')\n",
    "\n",
    "print(collections.Counter(y_train))\n",
    "print(collections.Counter(y_eda))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacia\n",
      "Emmbedings matrix....\n",
      "103870\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(103870, 300)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tokenizacia\")\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "sequences_train = tokenizer.texts_to_sequences(x_eda)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_seq = pad_sequences(sequences_train, maxlen=max_length) \n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=max_length)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "print(\"Emmbedings matrix....\")\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)\n",
    "embedding_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        [(None, 2500)]            0         \n",
      "_________________________________________________________________\n",
      "embedding_18 (Embedding)     (None, 2500, 300)         31161000  \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 31,397,289\n",
      "Trainable params: 31,397,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Trénovanie modelu...\n",
      "Epoch 1/5\n",
      "210/210 [==============================] - 915s 4s/step - loss: 0.4163 - acc: 0.8031 - val_loss: 0.1146 - val_acc: 0.9584\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95845, saving model to LSTM_eda_3metody.hdf5\n",
      "Epoch 2/5\n",
      "210/210 [==============================] - 909s 4s/step - loss: 0.0597 - acc: 0.9795 - val_loss: 0.0177 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.95845 to 0.99330, saving model to LSTM_eda_3metody.hdf5\n",
      "Epoch 3/5\n",
      "210/210 [==============================] - 904s 4s/step - loss: 0.0121 - acc: 0.9970 - val_loss: 0.0280 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.99330\n",
      "Epoch 4/5\n",
      "210/210 [==============================] - 905s 4s/step - loss: 9.5808e-04 - acc: 0.9998 - val_loss: 0.0532 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99330\n",
      "Epoch 5/5\n",
      "210/210 [==============================] - 906s 4s/step - loss: 2.0377e-04 - acc: 1.0000 - val_loss: 0.0683 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99330\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words,EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "saved_model= \"LSTM_eda_3metody.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "print('Trénovanie modelu...')\n",
    "history = model.fit(x_train_seq, y_eda,epochs=5, batch_size=32,callbacks=[checkpoint],validation_split=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model....\n",
      "Vyhodnotenie...\n",
      "Roc auc skóre je 0.9496371568195642\n",
      "Úspešnosť modelu je 0.9565789473684211\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98      1382\n",
      "           1       0.88      0.61      0.72       138\n",
      "\n",
      "    accuracy                           0.96      1520\n",
      "   macro avg       0.92      0.80      0.85      1520\n",
      "weighted avg       0.95      0.96      0.95      1520\n",
      "\n",
      "[[1370   12]\n",
      " [  54   84]]\n",
      "Počet real/fake v pôvodnej množine\n",
      "Counter({0: 5618, 1: 460})\n",
      "Počet real/fake v rozširenej množine\n",
      "Counter({0: 5618, 1: 1840})\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading model....\")\n",
    "model = load_model('LSTM_eda_3metody.hdf5')\n",
    "print(\"Vyhodnotenie...\")\n",
    "y_pred = model.predict(x_test_seq)\n",
    "print('Roc auc skóre je {}'.format(roc_auc_score(y_test,y_pred)))\n",
    "\n",
    "y_int = np.zeros_like(y_pred)\n",
    "y_int[y_pred > 0.5] = 1\n",
    "print('Úspešnosť modelu je {}'.format(accuracy_score(y_test,y_int)))\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))\n",
    "\n",
    "print(\"Počet real/fake v pôvodnej množine\")\n",
    "print(collections.Counter(y_train))\n",
    "print(\"Počet real/fake v rozširenej množine\")\n",
    "print(collections.Counter(y_eda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
