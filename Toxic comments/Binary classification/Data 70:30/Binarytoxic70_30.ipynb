{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas  as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Embedding, LSTM,  Flatten, Input,MaxPooling1D,  GlobalMaxPooling1D,Flatten, Dense, Dropout ,Conv1D\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import roc_auc_score , multilabel_confusion_matrix, accuracy_score\n",
    "from nltk.corpus import wordnet \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítanie dát...\n"
     ]
    }
   ],
   "source": [
    "print('Načítanie dát...')\n",
    "data= pd.read_csv(r'data_preprocess.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Celkový počet trénovacich príkladov je 1263411 z toho  92.03% je netoxických a 7.97% je toxických komentárov\n",
      "Celkový počet testovacich príkladov je 541463 z toho 91.94% je netoxických a 8.06% je toxických komentárov\n"
     ]
    }
   ],
   "source": [
    "x = data[\"comment_text\"].fillna(\"fillna\")\n",
    "y = data[\"target\"].values\n",
    "SEED = 42\n",
    "x_train,x_test, y_train ,y_test= train_test_split(x, y, test_size=0.3, random_state=SEED)\n",
    "\n",
    "print (\"Celkový počet trénovacich príkladov je {0} z toho  {1:.2f}% je netoxických a {2:.2f}% je toxických komentárov\".format(len(x_train),\n",
    "                      (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,(len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
    "\n",
    "print (\"Celkový počet testovacich príkladov je {0} z toho {1:.2f}% je netoxických a {2:.2f}% je toxických komentárov\".format(len(x_test),\n",
    "                      (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,(len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300 \n",
    "max_features = 50000 \n",
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítanie slovníka GloVe\n"
     ]
    }
   ],
   "source": [
    "print(\"Načítanie slovníka GloVe\")\n",
    "EMBEDDING_FILE = 'glove.840B.300d.txt' \n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('',EMBEDDING_FILE), encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizacia\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenizacia\")\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "sequences_train = tokenizer.texts_to_sequences(x_train)\n",
    "sequences_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = pad_sequences(sequences_train, maxlen=max_length) \n",
    "x_test_seq = pad_sequences(sequences_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emmbedings matica....\n",
      "328833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(328833, 300)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "print(\"Emmbedings matica....\")\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "print(num_words)\n",
    "embedding_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 200, 300)          98649900  \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 200, 64)           19264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 100, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 100, 64)           4160      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 50, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               409728    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 99,083,181\n",
      "Trainable params: 99,083,181\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Trénovanie modelu...\n",
      "Epoch 1/2\n",
      " 8133/35534 [=====>........................] - ETA: 12:40:11 - loss: 0.1772 - acc: 0.9381"
     ]
    }
   ],
   "source": [
    "####MODELOVANIE \n",
    "model= Sequential()\n",
    "e = Embedding(num_words,  EMBEDDING_DIM, weights=[embedding_matrix], input_length=max_length)\n",
    "model.add(e)\n",
    "model.add(Conv1D(filters=64, kernel_size=1, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(filters=64, kernel_size=1, padding='valid', activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "model.summary()\n",
    "\n",
    "saved_model = \"model7030.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "print('Trénovanie modelu...')\n",
    "history = model.fit(x_train_seq, y_train, batch_size=32, epochs=2, callbacks=[checkpoint], validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Načítanie modelu....\n",
      "Vyhodnotenie...\n",
      "Roc auc skóre je 0.9478020227619723\n",
      "Úspešnosť je 0.9470397792646958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97    497834\n",
      "           1       0.78      0.48      0.59     43629\n",
      "\n",
      "    accuracy                           0.95    541463\n",
      "   macro avg       0.87      0.73      0.78    541463\n",
      "weighted avg       0.94      0.95      0.94    541463\n",
      "\n",
      "Kontigenčná tabuľka\n",
      "[[491988   5846]\n",
      " [ 22830  20799]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Načítanie modelu....\")\n",
    "model = load_model('model7030.hdf5')\n",
    "print(\"Vyhodnotenie...\")\n",
    "y_pred = model.predict(x_test_seq)\n",
    "print('Roc auc skóre je {}'.format(roc_auc_score(y_test,y_pred)))\n",
    "\n",
    "y_int = np.zeros_like(y_pred)\n",
    "y_int[y_pred > 0.5] = 1\n",
    "print('Úspešnosť je {}'.format(accuracy_score(y_test,y_int)))\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(\"Kontigenčná tabuľka\")\n",
    "print(confusion_matrix(y_test, y_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
